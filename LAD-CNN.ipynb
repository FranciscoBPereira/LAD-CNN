{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer o download do dataset Flowers utilizando o Keras\n",
    "# As imagens ficam guardadas localmente em disco\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
    "                                   fname='flower_photos', \n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a diretoria em que se encontra o dataset\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número total de imagens\n",
    "\n",
    "total = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do Dataset a partir das imagens em disco\n",
    "# Este dataset ainda não está dividido. Em outros casos, já existem diretorias para os vários conjuntos\n",
    "\n",
    "# Neste exemplo são usados métodos do keras.preprocessing para carregar as imagens para o tf.data.dataset\n",
    "# Ver outras alternativas aqui: https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "# Define Batch size e dimensões das imagens\n",
    "# Não esquecer que as imagens têm 3 canais (RGB)\n",
    "# Cria conjunto de treino (80%) e de validação (20%)\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter alguma informação sobre o dataset\n",
    "\n",
    "#Cardinalidade \n",
    "print('Cardinalidade Treino: ', train_ds.cardinality().numpy())\n",
    "print('Cardinalidade Validacão: ', val_ds.cardinality().numpy())\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "print('Classes: ', class_names)\n",
    "\n",
    "\n",
    "# Explicar o valor obtido para a cardinalidade dos conjuntos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mostrar algumas imagens do Dataset\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "     for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter 2 imagens para análise mais detalhada \n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    im1 = images[0].numpy().astype(\"uint8\")\n",
    "    label1 = labels[0]\n",
    "    im2 = images[1].numpy().astype(\"uint8\")\n",
    "    label2 = labels[1]\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(im1)\n",
    "plt.title(class_names[label1])\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(im2)\n",
    "plt.title(class_names[label2])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte para Float e normaliza para intervalo [0, 1)\n",
    "im1_B = tf.image.convert_image_dtype(im1, dtype=tf.float32)\n",
    "\n",
    "# Ajusta para tensor com 4 dimensões (Batch + RGB)\n",
    "im1_B = tf.expand_dims(im1_B, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato do tensor que vai entrar como input na CNN\n",
    "# A primeira dimensão é o batch size\n",
    "\n",
    "im1_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar filtros verticais e horizontais \n",
    "\n",
    "filter1 = np.zeros(shape=(7,7,3, 1), dtype = np.float32)\n",
    "\n",
    "filter2 = np.zeros(shape=(7,7,3,1), dtype = np.float32)\n",
    "\n",
    "filter1[: , 3 , : ,] = 1\n",
    "filter2[3 , : , : ,] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = filter2.squeeze()\n",
    "R = a[:, :, 0]\n",
    "G = a[:, :, 1]\n",
    "B = a[:, :, 2]\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "plt.imshow(R)\n",
    "plt.title(\"R\")\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "plt.imshow(G)\n",
    "plt.title(\"G\")\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "plt.imshow(B)\n",
    "plt.title(\"B\")\n",
    "plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Escrever código para visualizar o filtro vertical\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar CNN a cada uma das imagens\n",
    "# Neste caso está a ser usado o método diretamente da biblioteca TensorFlow - Não estamos a usar a API Keras\n",
    "# Ainda não está a ser aplicada a função de ativação\n",
    "\n",
    "output1 = tf.nn.conv2d(im1_B, filter1, strides=1, padding=\"SAME\")\n",
    "output2 = tf.nn.conv2d(im1_B, filter2, strides=1, padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(output1[0,:,:], cmap=\"binary\")\n",
    "plt.title(\"Vertical\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(output2[0,:,:], cmap=\"binary\")\n",
    "plt.title(\"Horizontal\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Analisar os padrões que se salientam nas imagens obtidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar função de ativação RELU\n",
    "\n",
    "image1 = tf.nn.relu(output1)\n",
    "image2 = tf.nn.relu(output2)\n",
    "\n",
    "#x = image1[0,:,:]\n",
    "x = tf.squeeze(image1)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(tf.squeeze(image1), cmap=\"binary\")\n",
    "plt.title(\"Vertical\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(image2[0,:,:], cmap=\"binary\")\n",
    "plt.title(\"Horizontal\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercício: Qual a dimensão dos mapas de outputs em cada uma destas 3 situações?\n",
    "# Dimensões de input: Imagem (180, 180, 3), Filtro (7, 7, 3)\n",
    "\n",
    "outputE1 = tf.nn.conv2d(im1_B, filter1, strides=2, padding=\"SAME\")\n",
    "\n",
    "outputE2 = tf.nn.conv2d(im1_B, filter1, strides=1, padding=\"VALID\")\n",
    "\n",
    "outputE3 = tf.nn.conv2d(im1_B, filter1, strides=2, padding=\"VALID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmar se as previsões estão corretas, verificando o formato dos outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação de uma camada MaxPool\n",
    "\n",
    "pool1 = tf.nn.max_pool(image1, 2, strides=2, padding=\"SAME\")\n",
    "pool2 = tf.nn.max_pool(image2, 2, strides=2, padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirmar o Downsampling da imagem\n",
    "\n",
    "pool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.imshow(tf.squeeze(pool1), cmap=\"binary\")\n",
    "plt.title(\"Vertical\", fontsize=30)\n",
    "plt.axis(\"off\")\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.imshow(tf.squeeze(pool2), cmap=\"binary\")\n",
    "plt.title(\"Horizontal\", fontsize=30)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da CNN para classificação\n",
    "# Vai ser criado um modelo sequencial em que as camadas se sucedem umas às outras\n",
    "# https://www.tensorflow.org/guide/keras/sequential_model\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=[180, 180, 3]),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercício: Descrever as características desta CNN\n",
    "\n",
    "# Quais são as camadas de extração de features?\n",
    "\n",
    "# Quais são as camadas de classificação?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obter detalhes da segunda camada CNN (3ª camada da rede)\n",
    "\n",
    "my_layer = model.layers[2]\n",
    "my_layer.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = my_layer.get_weights()\n",
    "print(\"Weights Shape: \", weights.shape)\n",
    "print(\"Biases Shape: \", biases.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicar os valores obtidos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "# 1. Definir a função de loss: https://keras.io/api/losses/\n",
    "# 2. Definir o algoritmo de otimização/aprendizagem: https://keras.io/api/optimizers/\n",
    "# Definir a métrica de avaliação\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da evolução da accurary e da loss\n",
    "\n",
    "import pandas as pd \n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O que pode ser concluído das curvas em cima?\n",
    "\n",
    "# O que fazer para melhorar o desempenho?\n",
    "\n",
    "# Alterar a CNN, por forma a tentar melhorar o seu desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentar uma pequena fase de teste\n",
    "# Vamos usar algumas imagens e ver qual a classificação \n",
    "\n",
    "# Primeiro vamos usar uma imagem exemplo\n",
    "\n",
    "# Fazer o download da imagem e efetuar o pré-processamento\n",
    "\n",
    "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "\n",
    "img = keras.preprocessing.image.load_img(sunflower_path, target_size=(img_height, img_width))\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o modelo e obter a previsão\n",
    "\n",
    "predictions = model.predict(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "\n",
    "print(predictions.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(predictions)], 100 * np.max(predictions))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetir o processo para uma imagem à vossa escolha\n",
    "# Deve ser colocada na diretoria de trabalho onde têm o notebook\n",
    "\n",
    "nomeIm = 'ex.jpg'\n",
    "\n",
    "imX = tf.keras.preprocessing.image.load_img(nomeIm, target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetir o processo para a nova imagem\n",
    "\n",
    "imX_array = keras.preprocessing.image.img_to_array(imX)\n",
    "imX_array = tf.expand_dims(imX_array, 0) # Create a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(imX_array)\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(predictions)], 100 * np.max(predictions))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
